{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il nome DSC_3650.JPG è presente nel file Excel.\n",
      "Il nome DSC_4595.JPG è presente nel file Excel.\n",
      "Il nome Immagine 031.jpg è presente nel file Excel.\n",
      "Il nome DSCN2551.jpg è presente nel file Excel.\n",
      "Il nome DSCN9127.jpg è presente nel file Excel.\n",
      "Il numero di immagini ancora presenti nel file Excel è: 5.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica il file Excel\n",
    "rankings_df = pd.read_excel('../features/RANKINGS.xlsx', sheet_name='CBR FINAL', header=None)\n",
    "\n",
    "# Estrai i nomi delle colonne a partire dalla terza colonna\n",
    "start_column = 2  # Indice della terza colonna\n",
    "rankings_columns = rankings_df.iloc[0, start_column:].tolist()\n",
    "\n",
    "# Aggiungi i nomi dalla colonna A a partire dalla riga 4\n",
    "#column_A_names = rankings_df.iloc[3:, 0].tolist()\n",
    "#rankings_columns.extend(column_A_names)\n",
    "\n",
    "# Carica il file CSV\n",
    "classifier_df = pd.read_csv('../features/convnext_small_classifier.csv')\n",
    "\n",
    "# Estrai i nomi dalla colonna 'name'\n",
    "classifier_names = classifier_df['name'].tolist()\n",
    "\n",
    "immagini_mancanti = 0\n",
    "immagini_presenti = 0\n",
    "\n",
    "# Confronta i valori delle celle\n",
    "for name in classifier_names:\n",
    "    if name in rankings_columns:\n",
    "        print(f\"Il nome {name} è presente nel file Excel.\")\n",
    "        immagini_presenti += 1\n",
    "\n",
    "print(f\"Il numero di immagini ancora presenti nel file Excel è: {immagini_presenti}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id_casi', 'TIPO DI ULCERA', 'Immagine 031.jpg', '11-04-2008 015.jpg',\n",
      "       'Immagine 379.jpg', 'DSCN2162.JPG', 'DSCN2465.jpg', 'DSCN2549.jpg',\n",
      "       'DSCN2551.jpg', 'DSCN2702.JPG', 'DSCN9127.jpg', '4-06 033.jpg',\n",
      "       'DSC_1888.JPG', 'DSC_5396.JPG', 'Immagine 002.jpg', 'DSCN2477.jpg',\n",
      "       'DSC_6553.JPG', 'DSC_6482.JPG', 'DSCN5480.JPG', 'DSC_2957.JPG',\n",
      "       'DSC_0610.JPG', '893019313d524274b48aa1f318e6de5f.JPG',\n",
      "       '76d46b73787fbf1b746d9e5c717d0612.JPG', 'DSC_3645.JPG', 'DSC_3650.JPG',\n",
      "       'DSC_9556.JPG', 'DSCN8419.jpg', 'Immagine 0221.jpg', 'Immagine 213.jpg',\n",
      "       'imm 041.jpg', 'DSC_4595.JPG', 'Immagine 025.jpg',\n",
      "       '9af90f97dbf493dacb7bd83d66d420d1.jpg'],\n",
      "      dtype='object')\n",
      "['Immagine 010.jpg', 'DSC_7807.JPG', 'DSC_3261.JPG', 'DSC_9459.JPG', 'DSC_9220.JPG', 'DSC_7944.JPG', '0a2ab38bc6b1741e18c7d59319356e58.jpg', '28-05-2008 016.jpg', 'DSC_2974.JPG', 'DSCN8419 .jpg', 'Immagine 096.jpg', 'Immagine 247.jpg', 'DSC_3650.JPG', '3ac3a26a6d56e997d744e2cdfbbe9737.jpg', '40ec07a95ef7f52db5cc3513455d60cc.jpg', '9f8725243c3b743653350c60f64fb51b.JPG', 'DSCN4287.jpg', 'DSC_8691.JPG', '32c094b9e9020102948f73f52fa520e3.jpg', 'DSC_4595.JPG', 'DSC_4427.JPG', 'DSC_1480.JPG', '4fa81a5a2d2d8bb818c6ffaee409c998.JPG', 'DSC_6415.JPG', '4928c65f3b55b45077757abbd1b7f0c9.jpg', 'Immagine 133.jpg', 'DSCN3981.jpg', 'DSC_3118.JPG', 'DSC_4098.JPG', '65612a5a7fcee55e75e410cdef7924ae.jpg', 'e450c45e930e4199bb431c2b0055fe8a.JPG', 'DSC_9712.JPG', '38f5e82ab7437557bc24807419fcbea9.JPG', 'DSC_0143.JPG', 'fc60f3cf542b7842c1160463eb46e1eb.JPG', '7c0cda16b624d6022a57fb8970364444.JPG', 'DSCN1421.JPG', 'DSC_6517.JPG', 'DSC_81192.JPG', '80b1f09d2095954f038f6150b697369d.JPG', '5d284e411efcb9fa01f2d76217f0b09f.JPG', 'DSC_3473.JPG', '733fbbddaca3f39f66b924158a84f0a4.JPG', 'DSC_6877.JPG', '440caf7ed1178cae6f55c0385c595924.JPG', 'adea3cd26db33dbad396e3849c56a146.jpg', 'ced5b1d1c81346dfa214058737ec02e1.JPG', 'DSC_2830.JPG', 'c6cdc8915aa7d89a2442364690ccd7e2.JPG', 'Immagine 0212.jpg', 'Immagine 180.jpg', '6a5960c78102880d8acc069a2014fb0d.JPG', 'DSC_4068.JPG', '69e6bddd5dc267708fbc2a72bc3704f4.JPG', 'bff8ffa44b18f47f419bc204e06f74bd.JPG', '8bbd869cada25831ec94629aa0530a8a.jpg', 'a232a3456f2fe4d12aa96e1c7e086ee6.JPG', 'DSC_9074.JPG', 'DSCN1633.JPG', 'Immagine 017.jpg', '531027275e99c1f7d8975f748c1bdbc8.jpg', '4f7c41aa5111aa0f6721ec4408221c37.JPG', 'DSCN7757.jpg', 'Immagine 031.jpg', 'DSCN2221.jpg', 'DSCN2551.jpg', 'f95ccd64a6bdbbc4c6b4aab48d8128d0.jpg', 'DSC_4331.JPG', 'DSC_9425.JPG', '836c4e2a02cb4f5b0856f0fd9c17ef80.JPG', '28-05-2008 013.jpg', '6f5a7b21e6cdc5720c4c7f496ce4f2bb.jpg', 'b485225b419488c3d59eb893fb0a9ebd.jpg', '010.JPG', 'DSCN9127.jpg', 'DSC_9674.JPG', 'c447cee36c33c0579c6c08bd0b1db511.jpg', '7bc755d987dea554874af5d47c956022.jpg', 'DSC_8576.JPG', 'DSCN7924.jpg', 'Immagine 108.jpg', 'Immagine 382.jpg', 'DSC_9424.JPG', 'DSC_3507.JPG', 'Foto 27-11-2013 117.jpg', 'DSC_6084.JPG', 'DSC_9699.JPG', 'DSCN3315.JPG', 'DSCN7097.jpg', 'id_casi', 'TIPO DI ULCERA']\n",
      "['DSC_4595.JPG', 'DSCN9127.jpg', 'DSCN2551.jpg', 'DSC_3650.JPG', 'Immagine 031.jpg', 'id_casi', 'TIPO DI ULCERA']\n"
     ]
    }
   ],
   "source": [
    "# salvataggio in un file excel dei casi ancora presenti\n",
    "import pandas as pd\n",
    "\n",
    "# Carica il file Excel\n",
    "rankings_df = pd.read_excel('../features/RANKINGS.xlsx', sheet_name='CBR FINAL')\n",
    "\n",
    "# Estrai i nomi delle colonne a partire dalla prima colonna\n",
    "start_column = 0  # Indice della terza colonna\n",
    "rankings_columns = rankings_df.columns[start_column:]\n",
    "\n",
    "# Carica il file CSV\n",
    "classifier_df = pd.read_csv('../features/convnext_small_classifier.csv')\n",
    "\n",
    "# Estrai i nomi dalla colonna 'name'\n",
    "classifier_names = classifier_df['name'].tolist()\n",
    "# Aggiungi \"id_casi\" alla lista dei nomi\n",
    "classifier_names.append('id_casi')\n",
    "classifier_names.append('TIPO DI ULCERA')\n",
    "\n",
    "print(rankings_columns)\n",
    "print(classifier_names)\n",
    "# Trova i nomi comuni da mantenere\n",
    "common_names = list(set(rankings_columns) & set(classifier_names))\n",
    "print(common_names)\n",
    "# Seleziona solo le colonne del file Excel che corrispondono ai nomi presenti nel file CSV\n",
    "filtered_rankings_df = rankings_df[common_names]\n",
    "\n",
    "# Salva il DataFrame filtrato in un nuovo file Excel\n",
    "filtered_rankings_df.to_excel('../features/filtered_rankings.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica il file Excel\n",
    "rankings_df = pd.read_excel('../features/filtered_rankings.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Estrai il contenuto della colonna 'id_casi'\n",
    "ranking_ids = rankings_df['id_casi'].tolist()\n",
    "\n",
    "# Carica il file CSV\n",
    "classifier_df = pd.read_csv('../features/convnext_small_classifier.csv')\n",
    "\n",
    "# Estrai i nomi dalla colonna 'name'\n",
    "classifier_names = classifier_df['name'].tolist()\n",
    "# Aggiungi \"id_casi\" alla lista dei nomi\n",
    "classifier_names.append('id_casi')\n",
    "\n",
    "# Trova i nomi comuni da mantenere\n",
    "common_names = list(set(ranking_ids) & set(classifier_names))\n",
    "\n",
    "# Seleziona solo le righe del file Excel che corrispondono ai nomi presenti nel file CSV\n",
    "filtered_rankings_df = rankings_df[rankings_df['id_casi'].isin(common_names)] \n",
    "\n",
    "# Salva in un file CSV i casi ancora\n",
    "# Seleziona i nomi delle colonne che terminano con jpg o JPG da filtered_rankings_df\n",
    "column_names = filtered_rankings_df.columns[filtered_rankings_df.columns.str.endswith(('jpg', 'JPG'))]\n",
    "first_row_values = filtered_rankings_df.loc[0, column_names].tolist()\n",
    "column_names_df = pd.DataFrame({'CASI ANCORA': column_names, 'TIPO DI ULCERA': first_row_values})\n",
    "# sostituisci i valori della colonna 'TIPO DI ULCERA'\n",
    "column_names_df['TIPO DI ULCERA'] = column_names_df['TIPO DI ULCERA'].replace('NEOPLASTICA', 0)\n",
    "column_names_df['TIPO DI ULCERA'] = column_names_df['TIPO DI ULCERA'].replace('AFTOSA', 1)\n",
    "column_names_df['TIPO DI ULCERA'] = column_names_df['TIPO DI ULCERA'].replace('TRAUMATICA', 2)\n",
    "column_names_df.to_csv('casi_ancora.csv', index=False)\n",
    "\n",
    "# rimuovi la seconda riga\n",
    "filtered_rankings_df = filtered_rankings_df.drop(filtered_rankings_df.index[0])\n",
    "\n",
    "# sostituisci i valori della colonna 'TIPO DI ULCERA'\n",
    "filtered_rankings_df['TIPO DI ULCERA'] = filtered_rankings_df['TIPO DI ULCERA'].replace('NEOPLASTICA', 0)\n",
    "filtered_rankings_df['TIPO DI ULCERA'] = filtered_rankings_df['TIPO DI ULCERA'].replace('AFTOSA', 1)\n",
    "filtered_rankings_df['TIPO DI ULCERA'] = filtered_rankings_df['TIPO DI ULCERA'].replace('TRAUMATICA', 2)\n",
    "\n",
    "# controlla che non ci siano valori che si ripetono nella colonna 'id_casi', se ci sono mantiene solo la prima occorrenza\n",
    "filtered_rankings_df = filtered_rankings_df.drop_duplicates(subset='id_casi', keep='first')\n",
    "\n",
    "# Rimuovi i duplicati da ogni riga mantenendo solo la prima occorrenza di ciascun valore,\n",
    "# escludendo le colonne \"id_casi\" e \"TIPO DI ULCERA\"\n",
    "for index, row in filtered_rankings_df.iterrows():\n",
    "    columns_to_check = row.index.difference(['id_casi', 'TIPO DI ULCERA'])\n",
    "    filtered_rankings_df.loc[index, columns_to_check] = row[columns_to_check].drop_duplicates(keep='first')\n",
    "\n",
    "# Rimuovi le righe che contengono solo valori nulli\n",
    "for index, row in filtered_rankings_df.iterrows():\n",
    "    columns_to_check = row.index.difference(['id_casi', 'TIPO DI ULCERA'])\n",
    "    if row[columns_to_check].isnull().all():\n",
    "        filtered_rankings_df.drop(index, inplace=True)\n",
    "\n",
    "# Salva il DataFrame filtrato in un nuovo file CSV\n",
    "filtered_rankings_df.to_csv('../features/final_ranking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica i due file CSV\n",
    "df1 = pd.read_csv('../features/convnext_small_classifier.csv')\n",
    "df2 = pd.read_csv('../features/final_ranking.csv')\n",
    "df3 = pd.read_csv('../features/casi_ancora.csv')\n",
    "\n",
    "# Esegui il merge basato sulla colonna comune\n",
    "merged_df1 = pd.merge(df1, df2, left_on='name', right_on='id_casi', how='inner')\n",
    "merged_df2 = pd.merge(df1, df3, left_on='name', right_on='CASI ANCORA', how='inner')\n",
    "\n",
    "# Unisci i due DataFrame\n",
    "merged_df = pd.concat([merged_df1, merged_df2])\n",
    "\n",
    "#sostituisci le celle vuote con il valore 0\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "merged_df = merged_df.drop(columns=['id_casi'])\n",
    "merged_df = merged_df.drop(columns=['CASI ANCORA'])\n",
    "merged_df = merged_df.drop(columns=['TIPO DI ULCERA'])\n",
    "\n",
    "# Salva il DataFrame unito in un nuovo file CSV\n",
    "merged_df.to_csv('../features/merged_convnext_small_classifier.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica i due file CSV\n",
    "df1 = pd.read_csv('../features/squeezenet1_0_classifier.csv')\n",
    "df2 = pd.read_csv('../features/final_ranking.csv')\n",
    "df3 = pd.read_csv('../features/casi_ancora.csv')\n",
    "\n",
    "# Esegui il merge basato sulla colonna comune\n",
    "merged_df1 = pd.merge(df1, df2, left_on='name', right_on='id_casi', how='inner')\n",
    "merged_df2 = pd.merge(df1, df3, left_on='name', right_on='CASI ANCORA', how='inner')\n",
    "\n",
    "# Unisci i due DataFrame\n",
    "merged_df = pd.concat([merged_df1, merged_df2])\n",
    "\n",
    "#sostituisci le celle vuote con il valore 0\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "merged_df = merged_df.drop(columns=['id_casi'])\n",
    "merged_df = merged_df.drop(columns=['CASI ANCORA'])\n",
    "merged_df = merged_df.drop(columns=['TIPO DI ULCERA'])\n",
    "\n",
    "# Salva il DataFrame unito in un nuovo file CSV\n",
    "merged_df.to_csv('../features/merged_squeezenet1_0_classifier.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica i due file CSV\n",
    "df1 = pd.read_csv('../features/swin_s_head.csv')\n",
    "df2 = pd.read_csv('../features/final_ranking.csv')\n",
    "df3 = pd.read_csv('../features/casi_ancora.csv')\n",
    "\n",
    "# Esegui il merge basato sulla colonna comune\n",
    "merged_df1 = pd.merge(df1, df2, left_on='name', right_on='id_casi', how='inner')\n",
    "merged_df2 = pd.merge(df1, df3, left_on='name', right_on='CASI ANCORA', how='inner')\n",
    "\n",
    "# Unisci i due DataFrame\n",
    "merged_df = pd.concat([merged_df1, merged_df2])\n",
    "\n",
    "#sostituisci le celle vuote con il valore 0\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "merged_df = merged_df.drop(columns=['id_casi'])\n",
    "merged_df = merged_df.drop(columns=['CASI ANCORA'])\n",
    "merged_df = merged_df.drop(columns=['TIPO DI ULCERA'])\n",
    "\n",
    "# Salva il DataFrame unito in un nuovo file CSV\n",
    "merged_df.to_csv('../features/merged_swin_s_head.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica i due file CSV\n",
    "df1 = pd.read_csv('../features/vit_b_16_heads.csv')\n",
    "df2 = pd.read_csv('../features/final_ranking.csv')\n",
    "df3 = pd.read_csv('../features/casi_ancora.csv')\n",
    "\n",
    "# Esegui il merge basato sulla colonna comune\n",
    "merged_df1 = pd.merge(df1, df2, left_on='name', right_on='id_casi', how='inner')\n",
    "merged_df2 = pd.merge(df1, df3, left_on='name', right_on='CASI ANCORA', how='inner')\n",
    "\n",
    "# Unisci i due DataFrame\n",
    "merged_df = pd.concat([merged_df1, merged_df2])\n",
    "\n",
    "#sostituisci le celle vuote con il valore 0\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "merged_df = merged_df.drop(columns=['id_casi'])\n",
    "merged_df = merged_df.drop(columns=['CASI ANCORA'])\n",
    "merged_df = merged_df.drop(columns=['TIPO DI ULCERA'])\n",
    "\n",
    "# Salva il DataFrame unito in un nuovo file CSV\n",
    "merged_df.to_csv('../features/merged_vit_b_16_heads.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# controlla che nella riga ci sia almeno un valore diverso e uguale a 1 escludendo le ultime due colonne\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m row_subset\u001b[39m.\u001b[39meq(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39many() \u001b[39m&\u001b[39m row_subset\u001b[39m.\u001b[39mne(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39many():\n\u001b[1;32m     16\u001b[0m     \u001b[39m# utilizza il nome della colonna con valore 1 come positivo escludendo le ultime due colonne\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     positive \u001b[39m=\u001b[39m row[row_subset\u001b[39m.\u001b[39;49meq(\u001b[39m1\u001b[39;49m)]\u001b[39m.\u001b[39mindex[\u001b[39m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m     \u001b[39m# ogni valore diverso da 1 e diverso da nullo è un negativo escludendo le ultime due colonne\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     negatives \u001b[39m=\u001b[39m row[row_subset\u001b[39m.\u001b[39mne(\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m row_subset\u001b[39m.\u001b[39mnotnull()]\u001b[39m.\u001b[39mindex\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1068\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_slice(key)\n\u001b[1;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 1068\u001b[0m     key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex, key)\n\u001b[1;32m   1069\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_rows_with_mask(key)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:2575\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2573\u001b[0m indexer \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_indexer_for(index)\n\u001b[1;32m   2574\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39min\u001b[39;00m indexer:\n\u001b[0;32m-> 2575\u001b[0m     \u001b[39mraise\u001b[39;00m IndexingError(\n\u001b[1;32m   2576\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnalignable boolean Series provided as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mindexer (index of the boolean Series and of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2578\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe indexed object do not match).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2579\u001b[0m     )\n\u001b[1;32m   2581\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   2583\u001b[0m \u001b[39m# fall through for boolean\u001b[39;00m\n",
      "\u001b[0;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "# crea il file con le triplette per il contrastive learning\n",
    "import pandas as pd\n",
    "\n",
    "# Carica il file CSV\n",
    "df = pd.read_csv('../features/final_ranking.csv')\n",
    "\n",
    "# crea una lista vuota per contenere i DataFrame temporanei\n",
    "triplets_list = []\n",
    "\n",
    "# per ogni riga del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Seleziona solo le prime colonne escludendo le ultime due colonne\n",
    "    row_subset = row.iloc[:-2]\n",
    "    # controlla che nella riga ci sia almeno un valore diverso e uguale a 1 escludendo le ultime due colonne\n",
    "    if row_subset.eq(1).any() & row_subset.ne(1).any():\n",
    "        # utilizza il nome della colonna con valore 1 come positivo escludendo le ultime due colonne\n",
    "        positive = row_subset[row_subset.eq(1)].index[0]\n",
    "        # ogni valore diverso da 1 e diverso da nullo è un negativo escludendo le ultime due colonne\n",
    "        negatives = row_subset[row_subset.ne(1) & row_subset.notnull()].index\n",
    "        # salva il tipo di ulcera\n",
    "        ulcera = row['TIPO DI ULCERA']\n",
    "        # per ogni negativo crea una nuova riga\n",
    "        for negative in negatives:\n",
    "            triplets_list.append({'id_casi': row['id_casi'], 'positive': positive, 'negative': negative, 'TIPO DI ULCERA': ulcera})\n",
    "\n",
    "# Converti la lista di dizionari in un DataFrame\n",
    "triplets_df = pd.DataFrame(triplets_list)\n",
    "\n",
    "# Salva il DataFrame con le triplette in un nuovo file CSV\n",
    "triplets_df.to_csv('../features/triplets.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
